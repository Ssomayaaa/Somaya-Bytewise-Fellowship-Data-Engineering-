# -*- coding: utf-8 -*-
"""task8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jr_tbvTgPHCwtVMPyIyeRE4menK8U8rA
"""

pip install pyspark

from pyspark.sql import SparkSession

from pyspark.sql.functions import col, date_format, lower, when, substring, split, hour

spark = SparkSession.builder.getOrCreate()

spark

df = spark.read.format('csv') \
    .option('header', 'true') \
    .option('sep', ',') \
    .option('escape', '"') \
    .option('quote', '"') \
    .load('/content/sample_data/data.csv')  # sep, escape and quote to consider data with commas in it as a whole and not split data at comma

df.show(truncate=False, n=200)

df = df.filter(~(date_format(col("order_date"), "H").cast("int").between(0, 5)))

df.show(truncate=False)

df = df.withColumn(
    "time_of_day",
    when((hour(col("order_date")) >= 5) & (hour(col("order_date")) < 12), "morning")
    .when((hour(col("order_date")) >= 12) & (hour(col("order_date")) < 18), "afternoon")
    .when((hour(col("order_date")) >= 18) & (hour(col("order_date")) < 24), "evening")
)

# Reorder columns to place 'time_of_day' at index 1
columns = df.columns
desired_index = 1
# Remove 'time_of_day' from columns list to avoid duplication
columns.remove('time_of_day')
# Insert 'time_of_day' at the desired index
new_columns = columns[:desired_index] + ['time_of_day'] + columns[desired_index:]

# Reorder the DataFrame columns
orders_data = df.select(new_columns)

# Show the updated DataFrame
df.show(truncate=False)

df = df.filter(~lower(col("product")).contains("tv"))
df.show(truncate=False)

df = df.withColumn("product", lower(col("product")))
df = df.withColumn("category", lower(col("category")))
df = df.withColumn("purchase_state", split(col("purchase_address"), ",")[2])
df = df.withColumn("purchase_state", split(col("purchase_state"), " ")[1])
df.show(truncate=False)

output_path = "path_to_save_cleaned_data/cleaned_data.csv"
df.write.csv(output_path, header=True)